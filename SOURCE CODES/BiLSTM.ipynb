{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This model has two Bidirectional LSTM layers, with dropout layers added after each of them to prevent overfitting. The final output layer uses a sigmoid activation function to output a probability between 0 and 1 for binary classification."
      ],
      "metadata": {
        "id": "JwWnShfJFcuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset of tweets\n",
        "file_path = \"/content/drive/MyDrive/CS298/tweets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Clean the data\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
        "    text = re.sub(r'<.*?>', '', text) # Remove HTML tags\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
        "    text = re.sub(r'\\d+', '', text) # Remove digits\n",
        "    text = text.lower() # Convert text to lowercase\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8QvMAsUNxwb",
        "outputId": "0d91ab4f-2eb2-4aa0-b574-44e1a418bf52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['text'])\n",
        "X = tokenizer.texts_to_sequences(df['text'])\n",
        "maxlen = max(len(x) for x in X)\n",
        "X = pad_sequences(X, padding='post', maxlen=maxlen)\n",
        "\n",
        "# Create word embeddings using pre-trained GloVe embeddings\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word]\n",
        "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_matrix = create_embedding_matrix('/content/drive/MyDrive/CS298/glove.6B.100d.txt', tokenizer.word_index, embedding_dim)\n"
      ],
      "metadata": {
        "id": "WNNT9g8kNywK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj0AQAaUFbzj"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the BiLSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.2)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPJeT9_BN45i",
        "outputId": "0be004f4-9342-4ea0-dbb6-76cd062ea790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "191/191 [==============================] - 11s 38ms/step - loss: 0.4901 - accuracy: 0.7657 - val_loss: 0.4260 - val_accuracy: 0.8168\n",
            "Epoch 2/10\n",
            "191/191 [==============================] - 5s 26ms/step - loss: 0.4367 - accuracy: 0.8039 - val_loss: 0.4271 - val_accuracy: 0.8188\n",
            "Epoch 3/10\n",
            "191/191 [==============================] - 10s 50ms/step - loss: 0.4200 - accuracy: 0.8149 - val_loss: 0.4203 - val_accuracy: 0.8083\n",
            "Epoch 4/10\n",
            "191/191 [==============================] - 5s 27ms/step - loss: 0.4079 - accuracy: 0.8195 - val_loss: 0.4204 - val_accuracy: 0.8181\n",
            "Epoch 5/10\n",
            "191/191 [==============================] - 6s 33ms/step - loss: 0.3961 - accuracy: 0.8245 - val_loss: 0.4109 - val_accuracy: 0.8201\n",
            "Epoch 6/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.3841 - accuracy: 0.8327 - val_loss: 0.4148 - val_accuracy: 0.8148\n",
            "Epoch 7/10\n",
            "191/191 [==============================] - 6s 33ms/step - loss: 0.3728 - accuracy: 0.8345 - val_loss: 0.4371 - val_accuracy: 0.8135\n",
            "Epoch 8/10\n",
            "191/191 [==============================] - 5s 27ms/step - loss: 0.3554 - accuracy: 0.8455 - val_loss: 0.4349 - val_accuracy: 0.8043\n",
            "Epoch 9/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.3467 - accuracy: 0.8509 - val_loss: 0.4334 - val_accuracy: 0.8089\n",
            "Epoch 10/10\n",
            "191/191 [==============================] - 6s 30ms/step - loss: 0.3281 - accuracy: 0.8576 - val_loss: 0.4533 - val_accuracy: 0.8037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# Evaluate the model on the test set and get the predicted labels\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5) # Convert probabilities to binary labels\n",
        "\n",
        "# Get the true labels for the test set\n",
        "y_true = y_test\n",
        "\n",
        "# Calculate the evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "840W8x4gHa7h",
        "outputId": "07bb8c68-1b81-4a43-91a1-2a200c58ae3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8036769533814839\n",
            "Precision: 0.8038194444444444\n",
            "Recall: 0.7134052388289677\n",
            "F1 score: 0.7559183673469387\n"
          ]
        }
      ]
    }
  ]
}